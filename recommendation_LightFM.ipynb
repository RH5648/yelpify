{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_json('/Users/junheyang/Documents/uw2019-2020/CSE583/Project/yelpifydata/yelp_dataset/yelp_academic_dataset_review.json', lines=True, nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review.dropna(inplace=True)\n",
    "# review = review.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove \"new\" user/item pairs (for pure collaborative filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative filtering of dense interactions\n",
    "LENGTH = 5\n",
    "MAX_ITER = 100\n",
    "i = 0\n",
    "n_post = -1\n",
    "n_prev = 0\n",
    "for i in range(MAX_ITER):\n",
    "    print('iter: ', i)\n",
    "    n_pre = len(review)\n",
    "    print('n_pre: ', n_pre)\n",
    "    review = review.groupby('user_id').filter(lambda x: len(x)>LENGTH)\n",
    "    review = review.groupby('business_id').filter(lambda x: len(x)>LENGTH)\n",
    "    n_post = len(review)\n",
    "    print('n_post: ', n_post)\n",
    "    if n_post == n_pre:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review.to_csv('/Users/junheyang/Documents/uw2019-2020/CSE583/Project/yelpifydata/yelp_dataset/yelp_academic_dataset_review_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv('/Users/junheyang/Documents/uw2019-2020/CSE583/Project/yelpifydata/yelp_dataset/yelp_academic_dataset_review_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_json('/Users/junheyang/Documents/uw2019-2020/CSE583/Project/yelpifydata/yelp_dataset/yelp_academic_dataset_user.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_user = pd.merge(review, user, on = \"user_id\", how = \"left\", suffixes=(\"\",\"_user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(review_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_json('/Users/junheyang/Documents/uw2019-2020/CSE583/Project/yelpifydata/yelp_dataset/yelp_academic_dataset_business.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_user_business = pd.merge(review_user, business, on = \"business_id\", how = \"left\", suffixes=(\"\",\"_business\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(review_user_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_user_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_user_business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_user_business[['user_id', 'business_id', 'stars', 'text',\n",
    "                      'name', 'average_stars',\n",
    "                      'name_business', 'stars_business', 'categories', 'state', 'city']].to_parquet('/Users/junheyang/Documents/uw2019-2020/CSE583/Project/yelpifydata/yelp_dataset/data_clean.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different approaches: https://en.wikipedia.org/wiki/Recommender_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from lightfm import LightFM\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from lightfm.evaluation import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightfm.data import Dataset\n",
    "import swifter\n",
    "pd.options.display.max_columns = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/Users/junheyang/Documents/uw2019-2020/CSE583/Project/yelpifydata/yelp_dataset/data_clean.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_of_rating(number):\n",
    "    \"\"\"Round a number to the closest half integer.\n",
    "    >>> round_of_rating(1.3)\n",
    "    1.5\n",
    "    >>> round_of_rating(2.6)\n",
    "    2.5\n",
    "    >>> round_of_rating(3.0)\n",
    "    3.0\n",
    "    >>> round_of_rating(4.1)\n",
    "    4.0\"\"\"\n",
    "\n",
    "    return round(number * 2) / 2\n",
    "# bucketize numeric features to reduce dimensions\n",
    "df['average_stars'] = df['average_stars'].apply(lambda x: round_of_rating(x))\n",
    "df['stars_business'] = df['stars_business'].apply(lambda x: round_of_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and onehot encode category tags\n",
    "df_categories = df['categories'].str.get_dummies(sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep categories with more than 1% none-zero rows\n",
    "df_categories = df_categories[df_categories.columns[df_categories.sum()>len(df)*0.01]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.drop('categories', 1), df_categories], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we call fit to supply userid, item id and user/item features\n",
    "ds.fit(\n",
    "        df['user_id'].unique(), # all the users\n",
    "        df['business_id'].unique(), # all the items\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plugging in the interactions and their weights\n",
    "(train_interactions, train_weights) = ds.build_interactions([(x[0], x[1], x[2]) for x in train.values ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_interactions, test_weights) = ds.build_interactions([(x[0], x[1], x[2]) for x in test.values ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components=50, loss='warp')\n",
    "%time model.fit(train_interactions, sample_weight=train_weights, epochs=10, num_threads=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "train_auc = auc_score(model, train_interactions, num_threads=20).mean()\n",
    "print('Training set AUC: %s' % train_auc)\n",
    "test_auc = auc_score(model, test_interactions, num_threads=20).mean()\n",
    "print('Testing set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train precision: %.2f\" % precision_at_k(model, train_interactions, k=1, num_threads=20).mean())\n",
    "print(\"Test precision: %.2f\" % precision_at_k(model, test_interactions, k=1, num_threads=20).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train recall: %.2f\" % recall_at_k(model, train_interactions, k=10, num_threads=20).mean())\n",
    "print(\"Test recall: %.2f\" % recall_at_k(model, test_interactions, k=10, num_threads=20).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction for known users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain the model using the full dataset (not looking at train or test)\n",
    "ds_full = Dataset()\n",
    "# we call fit to supply userid, item id and user/item features\n",
    "ds_full.fit(\n",
    "        df['user_id'].unique(), # all the users\n",
    "        df['business_id'].unique(), # all the items\n",
    ")\n",
    "(interactions, weights) = ds_full.build_interactions([(x[0], x[1], x[2]) for x in df.values ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same model using the full dataset\n",
    "model_full = LightFM(no_components=50, loss='warp')\n",
    "%time model_full.fit(interactions, sample_weight=weights, epochs=10, num_threads=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_map, user_feature_map, business_id_map, business_feature_map = ds_full.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_known_user(model, interactions, user_id, user_dict, \n",
    "                               item_dict,threshold = 0,nrec_items = 10, show = True):\n",
    "    '''\n",
    "    Function to produce user recommendations\n",
    "    Required Input - \n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "        - user_id = user ID for which we need to generate recommendation\n",
    "        - user_dict = Dictionary type input containing user_id as key and interaction_index as value\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - threshold = value above which the rating is favorable in new interaction matrix\n",
    "        - nrec_items = Number of output recommendation needed\n",
    "    Expected Output - \n",
    "        - Prints list of items the given user has already visited\n",
    "        - Prints list of N recommended items  which user hopefully will be interested in\n",
    "    '''\n",
    "    n_users, n_items = interactions.shape\n",
    "    user_x = user_dict[user_id]\n",
    "    scores = pd.Series(model.predict(user_x,np.arange(n_items)))\n",
    "    scores.index = interactions.columns\n",
    "    scores = list(pd.Series(scores.sort_values(ascending=False).index))\n",
    "    \n",
    "    known_items = list(pd.Series(interactions.loc[user_id,:] \\\n",
    "                                 [interactions.loc[user_id,:] > threshold].index).sort_values(ascending=False))\n",
    "    \n",
    "    scores = [x for x in scores if x not in known_items]\n",
    "    return_score_list = scores[0:nrec_items]\n",
    "    known_items = list(pd.Series(known_items).apply(lambda x: item_dict[x]))\n",
    "    scores = list(pd.Series(return_score_list).apply(lambda x: item_dict[x]))\n",
    "    if show == True:\n",
    "        print(\"Known Likes:\")\n",
    "        counter = 1\n",
    "        for i in known_items:\n",
    "            print(str(counter) + '- ' + i)\n",
    "            counter+=1\n",
    "\n",
    "        print(\"\\n Recommended Items:\")\n",
    "        counter = 1\n",
    "        for i in scores:\n",
    "            print(str(counter) + '- ' + i)\n",
    "            counter+=1\n",
    "    return return_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interactions = pd.DataFrame(weights.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interactions.index = list(user_id_map.keys())\n",
    "df_interactions.columns = list(business_id_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = user_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict = df.set_index('business_id')['name_business'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_list_user = recommend_known_user(model = model_full, \n",
    "                                      interactions = df_interactions, \n",
    "                                      user_id = 'qRWzBX1q07ZuPgaTXB_4JA', \n",
    "                                      user_dict = user_dict,\n",
    "                                      item_dict = item_dict, \n",
    "                                      threshold = 3,\n",
    "                                      nrec_items = 10,\n",
    "                                      show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction for known businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interactions[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_known_item(model,interactions,item_id,user_dict,item_dict,number_of_user, show=True):\n",
    "    '''\n",
    "    Funnction to produce a list of top N interested users for a given item\n",
    "    Required Input -\n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "        - item_id = item ID for which we need to generate recommended users\n",
    "        - user_dict =  Dictionary type input containing user_id as key and interaction_index as value\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - number_of_user = Number of users needed as an output\n",
    "    Expected Output -\n",
    "        - user_list = List of recommended users \n",
    "    '''\n",
    "    n_users, n_items = interactions.shape\n",
    "    x = np.array(interactions.columns)\n",
    "    scores = pd.Series(model.predict(np.arange(n_users), np.repeat(x.searchsorted(item_id),n_users)))\n",
    "    user_list = list(interactions.index[scores.sort_values(ascending=False).head(number_of_user).index])\n",
    "    if show == True:\n",
    "        print(\"\\n Recommended Users:\")\n",
    "        counter = 1\n",
    "        for i in user_list:\n",
    "            print(str(counter) + '- ' + i)\n",
    "            counter+=1\n",
    "    return user_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_list_item = recommend_known_item(model = model_full,\n",
    "                           interactions = df_interactions,\n",
    "                           item_id = \"VMPSdoBgJuyS9t_x_caTig\",\n",
    "                           user_dict = user_dict,\n",
    "                           item_dict = item_dict,\n",
    "                           number_of_user = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid recommendation model (collaborative filtering + content-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "# we call fit to supply userid, item id and user/item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cols = ['user_id', 'average_stars']\n",
    "categories = [c for c in df.columns if c[0].isupper()]\n",
    "item_cols = ['business_id', 'stars_business', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_meta(df, cols):\n",
    "    results = []\n",
    "    for col in cols:\n",
    "        for v in df[col].unique():\n",
    "            results.append(col+':'+str(v))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = get_features_meta(df, user_cols[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = get_features_meta(df, item_cols[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.fit(\n",
    "        df['user_id'].unique(), # all the users\n",
    "        df['business_id'].unique(), # all the items\n",
    "        user_features = user_features, # additional user features\n",
    "        item_features = item_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that takes the user features and converts them into the proper \"feature:value\" format\n",
    "def get_features_tuple(row, id_col):\n",
    "    \"\"\"\n",
    "    Takes as input a list and prepends the columns names to respective values in the list.\n",
    "    For example: if my_list = {'uid': 'id', f1':1, 'f2': 1, 'f3':0, 'loc':'del'},\n",
    "    resultant output =(id, ['f1:1', 'f2:1', 'f3:0', 'loc:del'])\n",
    "   \n",
    "    \"\"\"\n",
    "    return (row[id_col], [k+':'+str(v) for k, v in row.items() if k!=id_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_features = train[user_cols].apply(lambda x: get_features_tuple(x, 'user_id'), axis=1).tolist()\n",
    "train_user_features = ds.build_user_features(train_user_features, normalize= False)\n",
    "\n",
    "test_user_features = test[user_cols].apply(lambda x: get_features_tuple(x, 'user_id'), axis=1).tolist()\n",
    "test_user_features = ds.build_user_features(test_user_features, normalize= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_features = train[item_cols].apply(lambda x: get_features_tuple(x, 'business_id'), axis=1).tolist()\n",
    "train_item_features = ds.build_item_features(train_item_features, normalize= False)\n",
    "\n",
    "test_item_features = test[item_cols].apply(lambda x: get_features_tuple(x, 'business_id'), axis=1).tolist()\n",
    "test_item_features = ds.build_item_features(test_item_features, normalize= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components=50, loss='warp')\n",
    "%time model.fit(train_interactions, user_features=train_user_features, item_features=train_item_features, epochs=10, num_threads=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auc = auc_score(model, train_interactions, user_features=train_user_features, item_features=train_item_features, num_threads=20).mean()\n",
    "print('Training set AUC: %s' % train_auc)\n",
    "test_auc = auc_score(model, test_interactions, user_features=test_user_features, item_features=test_item_features, num_threads=20).mean()\n",
    "print('Testing set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train precision: %.2f\" % precision_at_k(model, train_interactions, user_features=train_user_features, item_features=train_item_features, k=5, num_threads=20).mean())\n",
    "print(\"Test precision: %.2f\" % precision_at_k(model, test_interactions, user_features=test_user_features, item_features=test_item_features, k=5, num_threads=20).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
